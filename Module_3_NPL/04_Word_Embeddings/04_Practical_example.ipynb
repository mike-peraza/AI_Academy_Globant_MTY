{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical example and hands-on projects with Word Embeddings\n",
    "\n",
    "Here's an example of a practical project using Word Embeddings for text classification using the IMDb movie review dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Load the IMDb movie review dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# Preprocess the data\n",
    "max_length = 200\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_length)\n",
    "\n",
    "# Build the model\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, embedding_dim, input_length=max_length))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the trained model\n",
    "model.save('imdb_lstm_model.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Load the IMDb movie review dataset\n",
    "(_, _), (X_test, _) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# Load the trained Keras LSTM model\n",
    "model = load_model('imdb_lstm_model.h5')\n",
    "\n",
    "# Get the word index mapping from the dataset\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# Reverse the word index mapping\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# Function to convert sequence of word indices to words\n",
    "def sequence_to_words(sequence):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in sequence])\n",
    "\n",
    "# Example word pairs\n",
    "pairs = [('good', 'bad'), ('awesome', 'terrible'), ('amazing', 'awful')]\n",
    "\n",
    "# Compute similarity between pairs of words\n",
    "for pair in pairs:\n",
    "    word1, word2 = pair\n",
    "    word1_index = word_index.get(word1, -1)\n",
    "    word2_index = word_index.get(word2, -1)\n",
    "    \n",
    "    if word1_index != -1 and word2_index != -1:\n",
    "        # Get sequences from X_test\n",
    "        word1_sequence = np.array([X_test[word1_index]])\n",
    "        word2_sequence = np.array([X_test[word2_index]])\n",
    "\n",
    "        # Convert sequences to words\n",
    "        word1_text = sequence_to_words(word1_sequence[0])\n",
    "        word2_text = sequence_to_words(word2_sequence[0])\n",
    "\n",
    "        # Predict using the LSTM model\n",
    "        word1_vector = model.predict(word1_sequence)\n",
    "        word2_vector = model.predict(word2_sequence)\n",
    "\n",
    "        # Compute similarity between the vectors\n",
    "        similarity = np.dot(word1_vector.flatten(), word2_vector.flatten())\n",
    "        print(f\"Similarity between '{word1}' and '{word2}': {similarity}\")\n",
    "    else:\n",
    "        print(f\"One or both words not found in IMDb dataset: '{word1}' and '{word2}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code demonstrates a text classification task using Word Embeddings with an LSTM model. Here's an overview of the steps:\n",
    "\n",
    "Data Loading and Preprocessing:\n",
    "\n",
    "The IMDb movie review dataset is loaded using the imdb.load_data() function from Keras.\n",
    "The dataset is split into training and testing sets.\n",
    "The reviews are preprocessed by limiting the number of words to 10,000 and padding the sequences to a maximum length of 200 using sequence.pad_sequences().\n",
    "Model Building:\n",
    "\n",
    "The Sequential model from Keras is used to build the neural network.\n",
    "The Embedding layer is added as the input layer, which maps each word index to a dense vector representation.\n",
    "An LSTM layer is added to capture the sequential context of the reviews.\n",
    "A Dense layer with a sigmoid activation function is added as the output layer for binary classification.\n",
    "The model is compiled with the binary cross-entropy loss function and the Adam optimizer.\n",
    "Model Training and Evaluation:\n",
    "\n",
    "The model is trained using the fit() function, specifying the training data, batch size, and number of epochs.\n",
    "The model is evaluated on the test set using the evaluate() function, and the loss and accuracy are printed.\n",
    "This example demonstrates how to use Word Embeddings with an LSTM model for text classification. \n",
    "\n",
    "Other hands-on projects involving Word Embeddings could include sentiment analysis, named entity recognition, text generation, or even building a recommendation system. These projects would involve adapting the code and techniques to the specific task at hand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
