{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Now, let's put in practice some if the concepts learn in Pytorch. In this demo we will add some code to detect object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Importing Required Libraries\n",
    "First, make sure you have the required libraries installed. You can install them using pip if you haven't already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **torch**: The main PyTorch library for tensor operations and neural network building.\n",
    "- **torchvision**: A library for computer vision tasks that provides pre-trained models, datasets, and image transformations.\n",
    "- **transforms**: A module in torchvision for common image transformations.\n",
    "- **PIL**: Python Imaging Library, used here to open and manipulate images.\n",
    "- **matplotlib**: A plotting library used for visualizing images and drawing bounding boxes.\n",
    "- **patches**: A module from matplotlib used to create rectangles (bounding boxes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Loading Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)**: Loads a pre-trained Faster R-CNN model with a ResNet-50 backbone. The _pretrained=True_ argument specifies that the model weights are pre-trained on the COCO dataset.\n",
    "- **model.eval()**: Sets the model to evaluation mode, which is necessary for inference. This disables certain layers like dropout which are only used during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Function to Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img_path, threshold):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    pred = model([img])\n",
    "    pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())] # Get the Prediction Score\n",
    "    pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())] # Bounding boxes\n",
    "    pred_score = list(pred[0]['scores'].detach().numpy())\n",
    "    pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1]\n",
    "    pred_boxes = pred_boxes[:pred_t+1]\n",
    "    pred_class = pred_class[:pred_t+1]\n",
    "    return pred_boxes, pred_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **img_path**: Path to the input image.\n",
    "- **Image.open(img_path)**: Opens the image using PIL.\n",
    "- **transforms.Compose([transforms.ToTensor()])**: Creates a composition of transformations. Here, it converts the image to a tensor.\n",
    "- **img = transform(img)**: Applies the transformation to the image.\n",
    "- **model([img])**: Passes the image through the model to get predictions. The model expects a list of images, hence the [img].\n",
    "- **pred_class**: Extracts the class labels of the detected objects and converts them to readable class names using **COCO_INSTANCE_CATEGORY_NAMES**.\n",
    "- **pred_boxes**: Extracts the bounding boxes for the detected objects.\n",
    "- **pred_score**: Extracts the confidence scores for the detected objects.\n",
    "- **pred_t**: Filters the predictions based on the given threshold. Only predictions with a confidence score higher than the threshold are considered.\n",
    "- **pred_boxes** and **pred_class** are sliced to include only the predictions above the threshold.\n",
    "- **return pred_boxes, pred_class**: Returns the filtered bounding boxes and class names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Plot Image with Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_boxes(img_path, boxes, pred_cls):\n",
    "    img = Image.open(img_path)\n",
    "    fig, ax = plt.subplots(1, figsize=(12,9))\n",
    "    ax.imshow(img)\n",
    "    for box, cls in zip(boxes, pred_cls):\n",
    "        rect = patches.Rectangle(box[0], box[1][0] - box[0][0], box[1][1] - box[0][1], linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(box[0][0], box[0][1], cls, fontsize=12, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **img_path**: Path to the input image.\n",
    "- **boxes**: List of bounding boxes.\n",
    "- **pred_cls**: List of predicted class names.\n",
    "- **Image.open(img_path)**: Opens the image using PIL.\n",
    "- **fig, ax = plt.subplots(1, figsize=(12,9))**: Creates a subplot with a specific size for displaying the image.\n",
    "- **ax.imshow(img)**: Displays the image in the subplot.\n",
    "- **for box, cls in zip(boxes, pred_cls)**: Iterates through the bounding boxes and class names.\n",
    "- **patches.Rectangle**: Creates a rectangle (bounding box) with the specified coordinates, line width, and color.\n",
    "- **ax.add_patch(rect)**: Adds the rectangle to the subplot.\n",
    "- **plt.text(box[0][0], box[0][1], cls, fontsize=12, bbox=dict(facecolor='yellow', alpha=0.5))**: Adds a text label (class name) near the bounding box with a yellow background.\n",
    "- **plt.show()**: Displays the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. COCO Clases\n",
    "\n",
    "This list contains the class names for the COCO dataset, which the Faster R-CNN model is trained on. The indices of this list correspond to the class labels predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant',\n",
    "    'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A', 'handbag',\n",
    "    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
    "    'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli',\n",
    "    'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A',\n",
    "    'dining table', 'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock',\n",
    "    'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage\n",
    "\n",
    "Once, we have setup and define the needed functions, next step is to test it. For this, we will test 3 different images and see how the code behaves:\n",
    "\n",
    "1. **bird_test.png:** The code is able to predict it properly.\n",
    "2. **hotdog_test.png:** The code is able to predict it properly.\n",
    "3. **coco_test.png:** The code is cannot predict properly. It detects the object as a cake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../images/bird_test.png'  # Replace with your image path\n",
    "threshold = 0.8  # Confidence threshold\n",
    "boxes, pred_cls = get_prediction(img_path, threshold)\n",
    "plot_image_with_boxes(img_path, boxes, pred_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **img_path**: Path to the input image. Replace 'path/to/your/image.jpg' with the actual path.\n",
    "- **threshold**: Confidence threshold for filtering predictions. Only predictions with a score above this value will be considered.\n",
    "- **get_prediction(img_path, threshold)**: Calls the function to get the predictions.\n",
    "- **plot_image_with_boxes(img_path, boxes, pred_cls)**: Calls the function to plot the image with bounding boxes and class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this demo we explore one of many use cases where PyTorch can be used and how it can detect objects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
