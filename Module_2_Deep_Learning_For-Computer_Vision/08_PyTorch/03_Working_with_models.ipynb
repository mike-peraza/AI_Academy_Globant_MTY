{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Models\n",
    "\n",
    "There are different ways to build your deep learning model. You can achieve it using:\n",
    "\n",
    "- Supervised learning\n",
    "- Unsupervised learning\n",
    "- Semi-supervised learning. \n",
    "\n",
    "Despite the one you chose, you're going to use the same **pipeline** to **train, test, and deploy** your deep learning model. \n",
    "\n",
    "The process begins with the data preparation stage. As it's name suggests, we load the generic data, which can be in many different formats, such as text, images, videos, audio files, etc, from an external source, and we convert it to numeric values suitable for model training. These numeric values are in form of tensors. Then tensors need to be pre-processed during transforms, and we group them with batches that can be passed into the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Data preparation is the first step in developing a deep learning model. This step consists of loading the data, applying transforms, and batching the data using PyTorch built-in capabilities.\n",
    "\n",
    "We are going to use an existing popular academic dataset called CIFAR-10, developed by researchers from the Canadian Institute for Advanced Research. CIFAR-10 dataset is a subset of a much larger dataset with 80 million images in it. It consists of 60,000 small color photographs of objects from 10 classes divided into 50,000 training images and 10,000 test images. Here is the table with class labels and their associated integer values.\n",
    "\n",
    "\n",
    "| Integer Value | Class Label   |\n",
    "| ------------- | ------------- |\n",
    "|       0       | airplane      |\n",
    "|       1       | automobile    |\n",
    "|       2       | bird          |\n",
    "|       3       | cat           |\n",
    "|       4       | deer          |\n",
    "|       5       | dog           |\n",
    "|       6       | frog          |\n",
    "|       7       | horse         |\n",
    "|       8       | ship          |\n",
    "|       9       | truck         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Torchvision datasets module provides several subclasses to load image data from standard data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "from keras.datasets import cifar10\n",
    "from matplotlib import pyplot\n",
    "\n",
    "train_data = CIFAR10(root=\"./train/\", train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "# Summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainY.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images\n",
    "for i in range(16):\n",
    "    # define subplot\n",
    "    pyplot.subplot(4,4,i+1)\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(trainX[i])\n",
    "    # show the figure\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the training dataset\n",
    "\n",
    "When we print this shape, we see we have 50,000 images divided into 10 classes and corresponding labels. The label is an integer value that represents the class of the image. For example, airplane zero, automobile one, birds two, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.data.shape)\n",
    "print(train_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transforms\n",
    "\n",
    "Before passing the data into the model, usually we need to adjust it. For example, data values need to be converted from one type of object to a tensor. \n",
    "\n",
    "Another example of adjustment is data values that may be augmented to create a larger dataset. We can achieve this adjustment by applying transforms. PyTorch has a **torchvision library** that supports common computer vision transformations in the **_torchvision.transforms_** and **_torchvision.transforms.v2_** models. \n",
    "\n",
    "Transforms are common image transformations that we can use to transform or augment data for training or inference of different tasks. For example: image classification, detection, segmentation, and video classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "(tensor([[[-1.2854, -1.3629, -1.5180,  ...,  0.4981,  0.4593,  0.4399],\n",
      "         [-1.4986, -1.5761, -1.7312,  ...,  0.3430,  0.3236,  0.3236],\n",
      "         [-1.9057, -1.9832, -2.1383,  ...,  0.0522,  0.0522,  0.0716],\n",
      "         ...,\n",
      "         [ 1.0408,  1.0021,  0.9439,  ..., -0.3549, -0.5293, -0.6263],\n",
      "         [ 1.0214,  0.9827,  0.8858,  ...,  0.1297, -0.1223, -0.2386],\n",
      "         [ 1.0021,  0.9633,  0.8664,  ...,  0.3624,  0.0910, -0.0447]],\n",
      "\n",
      "        [[-1.1989, -1.2776, -1.4349,  ...,  0.0401,  0.0204,  0.0204],\n",
      "         [-1.3956, -1.4939, -1.6512,  ..., -0.1566, -0.1566, -0.1566],\n",
      "         [-1.8086, -1.9069, -2.1036,  ..., -0.5696, -0.5302, -0.5302],\n",
      "         ...,\n",
      "         [ 0.3351,  0.2564,  0.1188,  ..., -0.9826, -1.1202, -1.1792],\n",
      "         [ 0.3941,  0.3154,  0.1778,  ..., -0.4712, -0.6876, -0.8056],\n",
      "         [ 0.4138,  0.3351,  0.1974,  ..., -0.2156, -0.4712, -0.6089]],\n",
      "\n",
      "        [[-0.9922, -1.0703, -1.2459,  ..., -0.2313, -0.2118, -0.2118],\n",
      "         [-1.2069, -1.2849, -1.4605,  ..., -0.4655, -0.4460, -0.4264],\n",
      "         [-1.6166, -1.7141, -1.9092,  ..., -0.9532, -0.9142, -0.8752],\n",
      "         ...,\n",
      "         [-0.2509, -0.4655, -0.9142,  ..., -1.3239, -1.3629, -1.3629],\n",
      "         [-0.0558, -0.1923, -0.4850,  ..., -0.8752, -0.9532, -0.9922],\n",
      "         [ 0.0418, -0.0558, -0.2704,  ..., -0.6411, -0.7581, -0.8167]]]), 6)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "train_data_path = \"./train/\"\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    # These values are standard for CIFAR-10\n",
    "    # Without normalization, these values would typically range from zero to 255 \n",
    "    # for each channel, representing the intensity of RGB component of each pixel\n",
    "    transforms.Normalize(\n",
    "        mean= (0.4914, 0.4822, 0.4465),\n",
    "        std= (0.2023, 0.1994, 0.2010)\n",
    "    )\n",
    "])\n",
    "\n",
    "training_data = CIFAR10(train_data_path,\n",
    "                        train= True,\n",
    "                        download= True,\n",
    "                        transform= train_transforms)\n",
    "\n",
    "# Take a look at the transforms\n",
    "# Training data of first image\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development and Training\n",
    "\n",
    "After preparing data sets, we can finally explore model development. It consists of a few steps:\n",
    "\n",
    "- Model design\n",
    "- Training\n",
    "- Validation\n",
    "- Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define neural network, **init** and forward functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    # The forward function defines how data flows through the network \n",
    "    # in both training and making predictions\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "# define the Loss Function adn Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimaizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        (0.5, 0.5, 0.5),\n",
    "        (0.5, 0.5, 0.5)\n",
    "    )\n",
    "])\n",
    "\n",
    "train_set = CIFAR10(root='./data',\n",
    "                   train=True,\n",
    "                   download=True,\n",
    "                   transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = CIFAR10(root='./data',\n",
    "                   train=False,\n",
    "                   download=True,\n",
    "                   transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Network\n",
    "\n",
    "In the training step, our model learns by adjusting its weights based on the computed loss and gradients. It involves iterating over a data set multiple times, which we call epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.174\n",
      "[1,  4000] loss: 3.973\n",
      "[1,  6000] loss: 5.624\n",
      "[1,  8000] loss: 7.207\n",
      "[1, 10000] loss: 8.703\n",
      "[1, 12000] loss: 10.157\n",
      "[2,  2000] loss: 1.384\n",
      "[2,  4000] loss: 2.737\n",
      "[2,  6000] loss: 4.073\n",
      "[2,  8000] loss: 5.371\n",
      "[2, 10000] loss: 6.646\n",
      "[2, 12000] loss: 7.896\n",
      "[3,  2000] loss: 1.188\n",
      "[3,  4000] loss: 2.358\n",
      "[3,  6000] loss: 3.523\n",
      "[3,  8000] loss: 4.679\n",
      "[3, 10000] loss: 5.848\n",
      "[3, 12000] loss: 7.003\n",
      "[4,  2000] loss: 1.072\n",
      "[4,  4000] loss: 2.150\n",
      "[4,  6000] loss: 3.229\n",
      "[4,  8000] loss: 4.319\n",
      "[4, 10000] loss: 5.390\n",
      "[4, 12000] loss: 6.451\n",
      "[5,  2000] loss: 0.990\n",
      "[5,  4000] loss: 2.015\n",
      "[5,  6000] loss: 3.006\n",
      "[5,  8000] loss: 4.014\n",
      "[5, 10000] loss: 5.045\n",
      "[5, 12000] loss: 6.057\n",
      "[6,  2000] loss: 0.918\n",
      "[6,  4000] loss: 1.880\n",
      "[6,  6000] loss: 2.826\n",
      "[6,  8000] loss: 3.812\n",
      "[6, 10000] loss: 4.780\n",
      "[6, 12000] loss: 5.747\n",
      "[7,  2000] loss: 0.859\n",
      "[7,  4000] loss: 1.761\n",
      "[7,  6000] loss: 2.674\n",
      "[7,  8000] loss: 3.614\n",
      "[7, 10000] loss: 4.537\n",
      "[7, 12000] loss: 5.476\n",
      "[8,  2000] loss: 0.855\n",
      "[8,  4000] loss: 1.716\n",
      "[8,  6000] loss: 2.598\n",
      "[8,  8000] loss: 3.465\n",
      "[8, 10000] loss: 4.359\n",
      "[8, 12000] loss: 5.258\n",
      "[9,  2000] loss: 0.789\n",
      "[9,  4000] loss: 1.607\n",
      "[9,  6000] loss: 2.437\n",
      "[9,  8000] loss: 3.294\n",
      "[9, 10000] loss: 4.168\n",
      "[9, 12000] loss: 5.023\n",
      "[10,  2000] loss: 0.764\n",
      "[10,  4000] loss: 1.536\n",
      "[10,  6000] loss: 2.363\n",
      "[10,  8000] loss: 3.181\n",
      "[10, 10000] loss: 4.016\n",
      "[10, 12000] loss: 4.862\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train the network (10 minutes more or less to run the below code)\n",
    "\n",
    "# loop over the dataset multiple times\n",
    "for epoch in range(10):\n",
    "    # Initialize a variable to accumulate the loss over each batch\n",
    "    running_loss = 0.0\n",
    "    # This inner loop iterates over the training data set \n",
    "    # and the train loader provides batches of data, meaning images and labels\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a tuple of [input, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameters gradients\n",
    "        optimaizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        # After we pass the input data through the network to get outputs, \n",
    "        # we compute the loss by comparing the model's outputs with the actual labels.\n",
    "        loss = loss_function(outputs, labels)\n",
    "        # By calling loss.backward function, we perform a backward pass to compute \n",
    "        # the gradient of the loss with respect to the network parameters.\n",
    "        loss.backward()\n",
    "        optimaizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # print every 2,000 batches\n",
    "        if i%2000 == 1999:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation and Testing\n",
    "\n",
    "Validation and testing are important parts of model development as they take care that overfitting does not occur and that the model performs well against unseen data.\n",
    "\n",
    "In the validation step, we use a separate set of data, which we haven't used previously in training and call this set validation set. The main goal is tuning hip parameters such as learning rate or number of epochs, so we can provide an early indication of how our model is performing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this stage, we will need to modify the code on the load and transform section a bit as well as the Train the Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Refactor code for the Load and Transform step\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        (0.5, 0.5, 0.5),\n",
    "        (0.5, 0.5, 0.5)\n",
    "    )\n",
    "])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "      mean=(0.4914, 0.4822, 0.4465),\n",
    "      std=(0.2023, 0.1994, 0.2010)\n",
    "    )\n",
    "])\n",
    "\n",
    "train_data = CIFAR10(root=\"./train/\",\n",
    "                     train=True,\n",
    "                     download=True, \n",
    "                     transform=train_transforms)\n",
    "\n",
    "# trainset = CIFAR10(root='./data',\n",
    "#                    train=True,\n",
    "#                    download=True,\n",
    "#                    transform=transform)\n",
    "\n",
    "train_set, val_set = random_split(train_data,[40000, 10000])\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(\n",
    "#     train_set, \n",
    "#     batch_size=4, \n",
    "#     shuffle=True, \n",
    "#     num_workers=2)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True)\n",
    "\n",
    "# The test set is a separate data set that the model has never seen during training. \n",
    "# It provides us with a final evaluation of the model's performance. \n",
    "test_set = CIFAR10(root='./data',\n",
    "                   train=False,\n",
    "                   download=True,\n",
    "                   transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=4, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 1.0420414512515068, Validation Loss: 8.5669294257164, Validation Accuracy: 35.77%\n"
     ]
    }
   ],
   "source": [
    "# Refactor code for the Train Network step\n",
    "\n",
    "for epoch in range(10):\n",
    "    # Set the model to training mode\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimaizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimaizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    net.eval()  # Set the model to evaluation mode for validation\n",
    "    validation_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            validation_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Epoch {epoch + 1}, Training Loss: {running_loss / len(trainloader)}, Validation Loss: {validation_loss / len(valloader)}, Validation Accuracy: {100 * correct / total}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
